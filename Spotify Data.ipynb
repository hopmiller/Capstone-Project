{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf93bbd9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df603e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35275eb",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9fa21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/hopmiller/Desktop/Capstone/DataSets/Spotify_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce240278",
   "metadata": {},
   "source": [
    "### Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a62c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_submitted</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_thumbsup</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-09 15:00:00</td>\n",
       "      <td>Great music service, the audio is high quality...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-09 14:21:22</td>\n",
       "      <td>Please ignore previous negative rating. This a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-09 13:27:32</td>\n",
       "      <td>This pop-up \"Get the best Spotify experience o...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-09 13:26:45</td>\n",
       "      <td>Really buggy and terrible to use as of recently</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-09 13:20:49</td>\n",
       "      <td>Dear Spotify why do I get songs that I didn't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time_submitted                                             Review  \\\n",
       "0  2022-07-09 15:00:00  Great music service, the audio is high quality...   \n",
       "1  2022-07-09 14:21:22  Please ignore previous negative rating. This a...   \n",
       "2  2022-07-09 13:27:32  This pop-up \"Get the best Spotify experience o...   \n",
       "3  2022-07-09 13:26:45    Really buggy and terrible to use as of recently   \n",
       "4  2022-07-09 13:20:49  Dear Spotify why do I get songs that I didn't ...   \n",
       "\n",
       "   Rating  Total_thumbsup Reply  \n",
       "0       5               2   NaN  \n",
       "1       5               1   NaN  \n",
       "2       4               0   NaN  \n",
       "3       1               1   NaN  \n",
       "4       1               1   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a38a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61594, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae6b05",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bd4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hopmiller\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac20d61",
   "metadata": {},
   "source": [
    "#### Making word lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8368907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service, the audio is high quality...\n",
       "1    please ignore previous negative rating. this a...\n",
       "2    this pop-up \"get the best spotify experience o...\n",
       "3      really buggy and terrible to use as of recently\n",
       "4    dear spotify why do i get songs that i didn't ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review']=df['Review'].str.lower()\n",
    "# Previewing data\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2b3cd0",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57697d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service, audio high quality app ea...\n",
       "1    please ignore previous negative rating. app su...\n",
       "2    pop-up \"get best spotify experience android 12...\n",
       "3                   really buggy terrible use recently\n",
       "4    dear spotify get songs put playlist??? shuffle...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "df['Review'] = df['Review'].apply(lambda text: cleaning_stopwords(text))\n",
    "# Previewing data\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4cc14",
   "metadata": {},
   "source": [
    "### Standardizing strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74405e0",
   "metadata": {},
   "source": [
    "#### Removing puncutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab927c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    popup get best spotify experience android 12 a...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "def cleaning_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "df['Review']= df['Review'].apply(lambda x: cleaning_punctuations(x))\n",
    "# Preview data\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0122d",
   "metadata": {},
   "source": [
    "#### Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a8208b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    popup get best spotify experience android 12 a...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing Regular Expression\n",
    "import re\n",
    "\n",
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "df['Review'] = df['Review'].apply(lambda x: cleaning_URLs(x))\n",
    "# Preview\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ecc46",
   "metadata": {},
   "source": [
    "#### Removing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74fd3d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    popup get best spotify experience android   an...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', ' ', data)\n",
    "df['Review'] = df['Review'].apply(lambda x: cleaning_numbers(x))\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76d16c5",
   "metadata": {},
   "source": [
    "#### Removing short words \n",
    "I am opting to take out words with 2 or less characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa4fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    great music service audio high quality app eas...\n",
       "1    please ignore previous negative rating app sup...\n",
       "2    popup get best spotify experience android anno...\n",
       "3                   really buggy terrible use recently\n",
       "4     dear spotify get songs put playlist shuffle play\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_text(text):\n",
    "    return ' '.join([word for word in text.split() if len(word) > 2])\n",
    "df['Review'] = df['Review'].apply(lambda x: transform_text(x))\n",
    "# Preview data\n",
    "df['Review'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d550ce2",
   "metadata": {},
   "source": [
    "### Tokenization \n",
    "Using the Natural Language Toolkit, I will split the strings (reviews) into lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4901e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rating, a...\n",
       "2    [popup, get, best, spotify, experience, androi...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, songs, put, playlist, shu...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import word_tokenize from Natural Language Toolkit\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# creating a reference variable\n",
    "tt = TweetTokenizer()\n",
    "df['Review']=df['Review'].apply(tt.tokenize)\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84665e87",
   "metadata": {},
   "source": [
    "### Stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034aa76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rating, a...\n",
       "2    [popup, get, best, spotify, experience, androi...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, songs, put, playlist, shu...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "df['Review']= df['Review'].apply(lambda x: stemming_on_text(x))\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8417820",
   "metadata": {},
   "source": [
    "### Lemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca48b063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hopmiller\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [great, music, service, audio, high, quality, ...\n",
       "1    [please, ignore, previous, negative, rating, a...\n",
       "2    [popup, get, best, spotify, experience, androi...\n",
       "3             [really, buggy, terrible, use, recently]\n",
       "4    [dear, spotify, get, songs, put, playlist, shu...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "df['Review'] = df['Review'].apply(lambda x: lemmatizer_on_text(x))\n",
    "df['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6b641",
   "metadata": {},
   "source": [
    "## Tagging Reviews\n",
    "Creating a fucntion to tag the reivew as \"Positive\", \"Negative\", or \"Neutral\"\n",
    "\n",
    "I will assume a positive reviewer has also left an app rating that is postive. The critia is as follows:\n",
    "\n",
    "\n",
    "Positive = rating: 4-5\n",
    "\n",
    "Neutral = rating: 3\n",
    "\n",
    "Negative = rating: 1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400a714",
   "metadata": {},
   "source": [
    "### Creating a function to make a new column (Sentiment) to catagorize the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4ff6d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_submitted</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_thumbsup</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-09 15:00:00</td>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-09 14:21:22</td>\n",
       "      <td>[please, ignore, previous, negative, rating, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-09 13:27:32</td>\n",
       "      <td>[popup, get, best, spotify, experience, androi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-09 13:26:45</td>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-09 13:20:49</td>\n",
       "      <td>[dear, spotify, get, songs, put, playlist, shu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time_submitted                                             Review  \\\n",
       "0  2022-07-09 15:00:00  [great, music, service, audio, high, quality, ...   \n",
       "1  2022-07-09 14:21:22  [please, ignore, previous, negative, rating, a...   \n",
       "2  2022-07-09 13:27:32  [popup, get, best, spotify, experience, androi...   \n",
       "3  2022-07-09 13:26:45           [really, buggy, terrible, use, recently]   \n",
       "4  2022-07-09 13:20:49  [dear, spotify, get, songs, put, playlist, shu...   \n",
       "\n",
       "   Rating  Total_thumbsup Reply Sentiment  \n",
       "0       5               2   NaN  positive  \n",
       "1       5               1   NaN  positive  \n",
       "2       4               0   NaN  positive  \n",
       "3       1               1   NaN  negative  \n",
       "4       1               1   NaN  negative  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a function to compute the negative, neutral and positive analysis\n",
    "def getAnalysis(Rating):\n",
    "    if Rating<3:\n",
    "        return 'negative'\n",
    "    elif Rating==3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "    \n",
    "df['Sentiment']=df['Rating'].apply(getAnalysis)\n",
    "\n",
    "#show preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b9d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new dataframe all of the positive text\n",
    "df_positive = df[df['Sentiment'] == 'positive']\n",
    "\n",
    "\n",
    "# create two new dataframe all of the negative text\n",
    "df_negative = df[df['Sentiment'] == 'negative']\n",
    "\n",
    "\n",
    "# create two new dataframe all of the neutral text\n",
    "df_neutral=df[df['Sentiment'] == 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17e666",
   "metadata": {},
   "source": [
    "### Counting the number of each type of sentiment in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89eb2195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    29937\n",
       "negative    24771\n",
       "neutral      6886\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_counts = df.Sentiment.value_counts()\n",
    "review_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e574413",
   "metadata": {},
   "source": [
    "Most reviews are either positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc4386",
   "metadata": {},
   "source": [
    "# Training the Data\n",
    "Now that I have tagged the tweets as positive, negative, or neutral, it is time to train and test my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4219104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d264d15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_submitted</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total_thumbsup</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-09 15:00:00</td>\n",
       "      <td>[great, music, service, audio, high, quality, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-09 14:21:22</td>\n",
       "      <td>[please, ignore, previous, negative, rating, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-09 13:27:32</td>\n",
       "      <td>[popup, get, best, spotify, experience, androi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-09 13:26:45</td>\n",
       "      <td>[really, buggy, terrible, use, recently]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-09 13:20:49</td>\n",
       "      <td>[dear, spotify, get, songs, put, playlist, shu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time_submitted                                             Review  \\\n",
       "0  2022-07-09 15:00:00  [great, music, service, audio, high, quality, ...   \n",
       "1  2022-07-09 14:21:22  [please, ignore, previous, negative, rating, a...   \n",
       "2  2022-07-09 13:27:32  [popup, get, best, spotify, experience, androi...   \n",
       "3  2022-07-09 13:26:45           [really, buggy, terrible, use, recently]   \n",
       "4  2022-07-09 13:20:49  [dear, spotify, get, songs, put, playlist, shu...   \n",
       "\n",
       "   Rating  Total_thumbsup Reply Sentiment  \n",
       "0       5               2   NaN  positive  \n",
       "1       5               1   NaN  positive  \n",
       "2       4               0   NaN  positive  \n",
       "3       1               1   NaN  negative  \n",
       "4       1               1   NaN  negative  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4a72b",
   "metadata": {},
   "source": [
    "### Defining Sentiment\n",
    "Assigning a numerical value to each sentiment\n",
    "\n",
    "Postive = 2\n",
    "\n",
    "Negative = 0\n",
    "\n",
    "Neutral = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b9d9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into X and Y\n",
    "X = training_data['Review']\n",
    "Y = training_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96766a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = ['negative' , 'neutral', 'positive']\n",
    "Y = Y.apply(lambda x: sentiments.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b78941ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57983db1",
   "metadata": {},
   "source": [
    "### Vectorizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a09d058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_fit = count_vectorizer.fit_transform(df).toarray()\n",
    "\n",
    "# Check the shape\n",
    "X_fit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933f29c",
   "metadata": {},
   "source": [
    "## Making a Model\n",
    "I will be using MultinomialNB- type of Naive Bayes Classifier, which Calculates the probability of sentiment based on the probability of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ddbe713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (61.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (1.21.5)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hopmiller\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f94ee1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5535de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('Spotify_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "659dac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corpus.Review\n",
    "y = corpus.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a01145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "476618e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hopmiller\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9b84927",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff309b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6765f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_preparer(doc, stop_words=sw):\n",
    "    '''\n",
    "    \n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    \n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "    # print(doc)\n",
    "    doc = pos_tag(doc)\n",
    "    doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "    return ' '.join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f011e9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hopmiller\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "token_docs = [doc_preparer(doc, sw) for doc in X_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff7052c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary train-test split to build our best model\n",
    "X_test, X_val, y_test, y_val = train_test_split(token_docs, y_train,\n",
    "                                                test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55e5ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "X_test_vec = cv.fit_transform(X_test)\n",
    "X_test_vec = pd.DataFrame.sparse.from_spmatrix(X_test_vec)\n",
    "X_test_vec.columns = sorted(cv.vocabulary_)\n",
    "X_test_vec.set_index(y_test.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0866cfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaannndd</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aac</th>\n",
       "      <th>aada</th>\n",
       "      <th>aads</th>\n",
       "      <th>aah</th>\n",
       "      <th>...</th>\n",
       "      <th>zomato</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombify</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoner</th>\n",
       "      <th>zong</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zpotify</th>\n",
       "      <th>zumo</th>\n",
       "      <th>zuri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21450</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39666</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27421</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34646 rows × 14325 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaaaaaa  aaaannndd  aaah  aac  aada  aads  aah  ...  \\\n",
       "24466   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "21450   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "9456    0    0     0         0          0     0    0     0     0    0  ...   \n",
       "29030   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "57633   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "...    ..  ...   ...       ...        ...   ...  ...   ...   ...  ...  ...   \n",
       "16899   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "39666   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "58321   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "27421   0    0     0         0          0     0    0     0     0    0  ...   \n",
       "8511    0    0     0         0          0     0    0     0     0    0  ...   \n",
       "\n",
       "       zomato  zombie  zombify  zone  zoner  zong  zoom  zpotify  zumo  zuri  \n",
       "24466       0       0        0     0      0     0     0        0     0     0  \n",
       "21450       0       0        0     0      0     0     0        0     0     0  \n",
       "9456        0       0        0     0      0     0     0        0     0     0  \n",
       "29030       0       0        0     0      0     0     0        0     0     0  \n",
       "57633       0       0        0     0      0     0     0        0     0     0  \n",
       "...       ...     ...      ...   ...    ...   ...   ...      ...   ...   ...  \n",
       "16899       0       0        0     0      0     0     0        0     0     0  \n",
       "39666       0       0        0     0      0     0     0        0     0     0  \n",
       "58321       0       0        0     0      0     0     0        0     0     0  \n",
       "27421       0       0        0     0      0     0     0        0     0     0  \n",
       "8511        0       0        0     0      0     0     0        0     0     0  \n",
       "\n",
       "[34646 rows x 14325 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c1a61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vec = cv.transform(X_val)\n",
    "X_val_vec  = pd.DataFrame.sparse.from_spmatrix(X_val_vec)\n",
    "X_val_vec.columns = sorted(cv.vocabulary_)\n",
    "X_val_vec.set_index(y_val.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5369044e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0a1f978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.89      0.72      9987\n",
      "           2       0.62      0.25      0.35      4021\n",
      "           3       0.63      0.24      0.35      3845\n",
      "           4       0.53      0.35      0.43      4423\n",
      "           5       0.79      0.88      0.83     12370\n",
      "\n",
      "    accuracy                           0.67     34646\n",
      "   macro avg       0.64      0.52      0.54     34646\n",
      "weighted avg       0.67      0.67      0.64     34646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnb.predict(X_test_vec)\n",
    "from sklearn.metrics import classification_report\n",
    "classification = classification_report(y_test,y_pred)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c55745fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hopmiller\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "plot_confusion_matrix only supports classifiers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:88\u001b[0m, in \u001b[0;36mdeprecated._decorate_fun.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:563\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[0;32m    560\u001b[0m check_matplotlib_support(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_confusion_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_classifier(estimator):\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplot_confusion_matrix only supports classifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    565\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    566\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\n\u001b[0;32m    567\u001b[0m     y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, labels\u001b[38;5;241m=\u001b[39mlabels, normalize\u001b[38;5;241m=\u001b[39mnormalize\n\u001b[0;32m    568\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: plot_confusion_matrix only supports classifiers"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plot_confusion_matrix(classification, X_test_vec, y_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c7a11",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40943d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
